"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from .datacollection import DataCollection
from .preferredmaxlatency import PreferredMaxLatency, PreferredMaxLatencyTypedDict
from .preferredminthroughput import (
    PreferredMinThroughput,
    PreferredMinThroughputTypedDict,
)
from .providername import ProviderName
from .providersort import ProviderSort
from .quantization import Quantization
from openrouter.types import (
    BaseModel,
    Nullable,
    OptionalNullable,
    UNSET,
    UNSET_SENTINEL,
    UnrecognizedStr,
)
from openrouter.utils import validate_open_enum
from pydantic import model_serializer
from pydantic.functional_validators import PlainValidator
from typing import List, Literal, Optional, Union
from typing_extensions import Annotated, NotRequired, TypeAliasType, TypedDict


ProviderPreferencesOrderTypedDict = TypeAliasType(
    "ProviderPreferencesOrderTypedDict", Union[ProviderName, str]
)


ProviderPreferencesOrder = TypeAliasType(
    "ProviderPreferencesOrder",
    Union[Annotated[ProviderName, PlainValidator(validate_open_enum(False))], str],
)


ProviderPreferencesOnlyTypedDict = TypeAliasType(
    "ProviderPreferencesOnlyTypedDict", Union[ProviderName, str]
)


ProviderPreferencesOnly = TypeAliasType(
    "ProviderPreferencesOnly",
    Union[Annotated[ProviderName, PlainValidator(validate_open_enum(False))], str],
)


ProviderPreferencesIgnoreTypedDict = TypeAliasType(
    "ProviderPreferencesIgnoreTypedDict", Union[ProviderName, str]
)


ProviderPreferencesIgnore = TypeAliasType(
    "ProviderPreferencesIgnore",
    Union[Annotated[ProviderName, PlainValidator(validate_open_enum(False))], str],
)


SortEnum = Union[
    Literal[
        "price",
        "throughput",
        "latency",
    ],
    UnrecognizedStr,
]


ProviderSortConfigEnum = Literal[
    "price",
    "throughput",
    "latency",
]


ProviderPreferencesPartition = Union[
    Literal[
        "model",
        "none",
    ],
    UnrecognizedStr,
]


class ProviderPreferencesProviderSortConfigTypedDict(TypedDict):
    by: NotRequired[Nullable[ProviderSort]]
    partition: NotRequired[Nullable[ProviderPreferencesPartition]]


class ProviderPreferencesProviderSortConfig(BaseModel):
    by: Annotated[
        OptionalNullable[ProviderSort], PlainValidator(validate_open_enum(False))
    ] = UNSET

    partition: Annotated[
        OptionalNullable[ProviderPreferencesPartition],
        PlainValidator(validate_open_enum(False)),
    ] = UNSET

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = ["by", "partition"]
        nullable_fields = ["by", "partition"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


ProviderSortConfigUnionTypedDict = TypeAliasType(
    "ProviderSortConfigUnionTypedDict",
    Union[ProviderPreferencesProviderSortConfigTypedDict, ProviderSortConfigEnum],
)


ProviderSortConfigUnion = TypeAliasType(
    "ProviderSortConfigUnion",
    Union[ProviderPreferencesProviderSortConfig, ProviderSortConfigEnum],
)


ProviderPreferencesProviderSort = Union[
    Literal[
        "price",
        "throughput",
        "latency",
    ],
    UnrecognizedStr,
]


ProviderPreferencesSortUnionTypedDict = TypeAliasType(
    "ProviderPreferencesSortUnionTypedDict",
    Union[ProviderPreferencesProviderSort, ProviderSortConfigUnionTypedDict, SortEnum],
)
r"""The sorting strategy to use for this request, if \"order\" is not specified. When set, no load balancing is performed."""


ProviderPreferencesSortUnion = TypeAliasType(
    "ProviderPreferencesSortUnion",
    Union[
        Annotated[
            ProviderPreferencesProviderSort, PlainValidator(validate_open_enum(False))
        ],
        ProviderSortConfigUnion,
        Annotated[SortEnum, PlainValidator(validate_open_enum(False))],
    ],
)
r"""The sorting strategy to use for this request, if \"order\" is not specified. When set, no load balancing is performed."""


class ProviderPreferencesMaxPriceTypedDict(TypedDict):
    r"""The object specifying the maximum price you want to pay for this request. USD price per million tokens, for prompt and completion."""

    prompt: NotRequired[str]
    r"""Price per million prompt tokens"""
    completion: NotRequired[str]
    image: NotRequired[str]
    audio: NotRequired[str]
    request: NotRequired[str]


class ProviderPreferencesMaxPrice(BaseModel):
    r"""The object specifying the maximum price you want to pay for this request. USD price per million tokens, for prompt and completion."""

    prompt: Optional[str] = None
    r"""Price per million prompt tokens"""

    completion: Optional[str] = None

    image: Optional[str] = None

    audio: Optional[str] = None

    request: Optional[str] = None


class ProviderPreferencesTypedDict(TypedDict):
    r"""Provider routing preferences for the request."""

    allow_fallbacks: NotRequired[Nullable[bool]]
    r"""Whether to allow backup providers to serve requests
    - true: (default) when the primary provider (or your custom providers in \"order\") is unavailable, use the next best provider.
    - false: use only the primary/custom provider, and return the upstream error if it's unavailable.

    """
    require_parameters: NotRequired[Nullable[bool]]
    r"""Whether to filter providers to only those that support the parameters you've provided. If this setting is omitted or set to false, then providers will receive only the parameters they support, and ignore the rest."""
    data_collection: NotRequired[Nullable[DataCollection]]
    r"""Data collection setting. If no available model provider meets the requirement, your request will return an error.
    - allow: (default) allow providers which store user data non-transiently and may train on it

    - deny: use only providers which do not collect user data.
    """
    zdr: NotRequired[Nullable[bool]]
    r"""Whether to restrict routing to only ZDR (Zero Data Retention) endpoints. When true, only endpoints that do not retain prompts will be used."""
    enforce_distillable_text: NotRequired[Nullable[bool]]
    r"""Whether to restrict routing to only models that allow text distillation. When true, only models where the author has allowed distillation will be used."""
    order: NotRequired[Nullable[List[ProviderPreferencesOrderTypedDict]]]
    r"""An ordered list of provider slugs. The router will attempt to use the first provider in the subset of this list that supports your requested model, and fall back to the next if it is unavailable. If no providers are available, the request will fail with an error message."""
    only: NotRequired[Nullable[List[ProviderPreferencesOnlyTypedDict]]]
    r"""List of provider slugs to allow. If provided, this list is merged with your account-wide allowed provider settings for this request."""
    ignore: NotRequired[Nullable[List[ProviderPreferencesIgnoreTypedDict]]]
    r"""List of provider slugs to ignore. If provided, this list is merged with your account-wide ignored provider settings for this request."""
    quantizations: NotRequired[Nullable[List[Quantization]]]
    r"""A list of quantization levels to filter the provider by."""
    sort: NotRequired[Nullable[ProviderPreferencesSortUnionTypedDict]]
    max_price: NotRequired[ProviderPreferencesMaxPriceTypedDict]
    r"""The object specifying the maximum price you want to pay for this request. USD price per million tokens, for prompt and completion."""
    preferred_min_throughput: NotRequired[Nullable[PreferredMinThroughputTypedDict]]
    r"""Preferred minimum throughput (in tokens per second). Can be a number (applies to p50) or an object with percentile-specific cutoffs. Endpoints below the threshold(s) may still be used, but are deprioritized in routing. When using fallback models, this may cause a fallback model to be used instead of the primary model if it meets the threshold."""
    preferred_max_latency: NotRequired[Nullable[PreferredMaxLatencyTypedDict]]
    r"""Preferred maximum latency (in seconds). Can be a number (applies to p50) or an object with percentile-specific cutoffs. Endpoints above the threshold(s) may still be used, but are deprioritized in routing. When using fallback models, this may cause a fallback model to be used instead of the primary model if it meets the threshold."""


class ProviderPreferences(BaseModel):
    r"""Provider routing preferences for the request."""

    allow_fallbacks: OptionalNullable[bool] = UNSET
    r"""Whether to allow backup providers to serve requests
    - true: (default) when the primary provider (or your custom providers in \"order\") is unavailable, use the next best provider.
    - false: use only the primary/custom provider, and return the upstream error if it's unavailable.

    """

    require_parameters: OptionalNullable[bool] = UNSET
    r"""Whether to filter providers to only those that support the parameters you've provided. If this setting is omitted or set to false, then providers will receive only the parameters they support, and ignore the rest."""

    data_collection: Annotated[
        OptionalNullable[DataCollection], PlainValidator(validate_open_enum(False))
    ] = UNSET
    r"""Data collection setting. If no available model provider meets the requirement, your request will return an error.
    - allow: (default) allow providers which store user data non-transiently and may train on it

    - deny: use only providers which do not collect user data.
    """

    zdr: OptionalNullable[bool] = UNSET
    r"""Whether to restrict routing to only ZDR (Zero Data Retention) endpoints. When true, only endpoints that do not retain prompts will be used."""

    enforce_distillable_text: OptionalNullable[bool] = UNSET
    r"""Whether to restrict routing to only models that allow text distillation. When true, only models where the author has allowed distillation will be used."""

    order: OptionalNullable[List[ProviderPreferencesOrder]] = UNSET
    r"""An ordered list of provider slugs. The router will attempt to use the first provider in the subset of this list that supports your requested model, and fall back to the next if it is unavailable. If no providers are available, the request will fail with an error message."""

    only: OptionalNullable[List[ProviderPreferencesOnly]] = UNSET
    r"""List of provider slugs to allow. If provided, this list is merged with your account-wide allowed provider settings for this request."""

    ignore: OptionalNullable[List[ProviderPreferencesIgnore]] = UNSET
    r"""List of provider slugs to ignore. If provided, this list is merged with your account-wide ignored provider settings for this request."""

    quantizations: OptionalNullable[
        List[Annotated[Quantization, PlainValidator(validate_open_enum(False))]]
    ] = UNSET
    r"""A list of quantization levels to filter the provider by."""

    sort: OptionalNullable[ProviderPreferencesSortUnion] = UNSET

    max_price: Optional[ProviderPreferencesMaxPrice] = None
    r"""The object specifying the maximum price you want to pay for this request. USD price per million tokens, for prompt and completion."""

    preferred_min_throughput: OptionalNullable[PreferredMinThroughput] = UNSET
    r"""Preferred minimum throughput (in tokens per second). Can be a number (applies to p50) or an object with percentile-specific cutoffs. Endpoints below the threshold(s) may still be used, but are deprioritized in routing. When using fallback models, this may cause a fallback model to be used instead of the primary model if it meets the threshold."""

    preferred_max_latency: OptionalNullable[PreferredMaxLatency] = UNSET
    r"""Preferred maximum latency (in seconds). Can be a number (applies to p50) or an object with percentile-specific cutoffs. Endpoints above the threshold(s) may still be used, but are deprioritized in routing. When using fallback models, this may cause a fallback model to be used instead of the primary model if it meets the threshold."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = [
            "allow_fallbacks",
            "require_parameters",
            "data_collection",
            "zdr",
            "enforce_distillable_text",
            "order",
            "only",
            "ignore",
            "quantizations",
            "sort",
            "max_price",
            "preferred_min_throughput",
            "preferred_max_latency",
        ]
        nullable_fields = [
            "allow_fallbacks",
            "require_parameters",
            "data_collection",
            "zdr",
            "enforce_distillable_text",
            "order",
            "only",
            "ignore",
            "quantizations",
            "sort",
            "preferred_min_throughput",
            "preferred_max_latency",
        ]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m
